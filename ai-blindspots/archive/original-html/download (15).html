<!doctype html><html lang=en-us><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Scientific Debugging | AI Blindspots</title>
<meta name=title content="Scientific Debugging"><meta name=description content="When there is a bug, there are broadly two ways you can try to fix it.  One
way is to randomly try things based on vibes and hope you get lucky.  The
other is to systematically examine your assumptions about how the system works
and figure out where reality mismatches your expectations.  I generally think
that the second approach of scientific debugging is better in the long run;
even if it takes you more time to do, you will walk away with a better
understanding of the codebase for next time."><meta name=keywords content><meta property="og:url" content="https://ezyang.github.io/ai-blindspots/scientific-debugging/"><meta property="og:site_name" content="AI Blindspots"><meta property="og:title" content="Scientific Debugging"><meta property="og:description" content="When there is a bug, there are broadly two ways you can try to fix it. One way is to randomly try things based on vibes and hope you get lucky. The other is to systematically examine your assumptions about how the system works and figure out where reality mismatches your expectations. I generally think that the second approach of scientific debugging is better in the long run; even if it takes you more time to do, you will walk away with a better understanding of the codebase for next time."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-03-09T22:18:30-04:00"><meta property="article:modified_time" content="2025-03-09T22:18:30-04:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Scientific Debugging"><meta name=twitter:description content="When there is a bug, there are broadly two ways you can try to fix it. One way is to randomly try things based on vibes and hope you get lucky. The other is to systematically examine your assumptions about how the system works and figure out where reality mismatches your expectations. I generally think that the second approach of scientific debugging is better in the long run; even if it takes you more time to do, you will walk away with a better understanding of the codebase for next time."><meta itemprop=name content="Scientific Debugging"><meta itemprop=description content="When there is a bug, there are broadly two ways you can try to fix it. One way is to randomly try things based on vibes and hope you get lucky. The other is to systematically examine your assumptions about how the system works and figure out where reality mismatches your expectations. I generally think that the second approach of scientific debugging is better in the long run; even if it takes you more time to do, you will walk away with a better understanding of the codebase for next time."><meta itemprop=datePublished content="2025-03-09T22:18:30-04:00"><meta itemprop=dateModified content="2025-03-09T22:18:30-04:00"><meta itemprop=wordCount content="315"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:800px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fff;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--code-background-color:#f2f2f2;--code-color:#222;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#333;--heading-color:#eee;--text-color:#ddd;--link-color:#8cc2dd;--visited-color:#8b6fcb;--code-background-color:#777;--code-color:#ddd;--blockquote-color:#ccc}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px}blockquote{border-left:1px solid #999;color:var(--code-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto!important}.highlight,.code{padding:1px 15px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style></head><body><header><a href=/ai-blindspots/ class=title><h2>AI Blindspots</h2></a><nav><a href=/ai-blindspots/>Home</a>
<a href=/ai-blindspots/blog>Blog</a></nav></header><main><h1>Scientific Debugging</h1><p><i><time datetime=2025-03-09>2025-03-09</time></i></p><content><p>When there is a bug, there are broadly two ways you can try to fix it. One
way is to randomly try things based on vibes and hope you get lucky. The
other is to systematically examine your assumptions about how the system works
and figure out where reality mismatches your expectations. I generally think
that the second approach of scientific debugging is better in the long run;
even if it takes you more time to do, you will walk away with a better
understanding of the codebase for next time.</p><p>A non-reasoning model is not going to do the scientific method. It is going
to &ldquo;guess&rdquo; what the fix is, and try to one shot it. If you are in an agent
loop, it can rerun the test suite to see if it worked or not, and then
randomly try things until it succeeds (but more likely, gets into a death
loop).</p><p>The general word on the street is you should use a reasoning model for
debugging (actually, people tend to prefer using models like Grok 3 or
DeepSeek-R1 for this sort of problem). Personally, when I do AI coding, I am
still maintaining a pretty detailed mental model of how the code is supposed
to work, so I think it&rsquo;s pretty reasonable to also try to root cause it yourself (you don&rsquo;t have to fix it, if you tell the model what&rsquo;s wrong it will usually do the right thing).</p><h2 id=examples>Examples</h2><ul><li>One of the most horrifying death loops an agent LLM can get into is trying
to fix misconfigurations in your environment; e.g., a package is missing for
some reason. One funny problem with Sonnet 3.7 is that it expects <code>pip</code> to
be available, which it&rsquo;s not in the default venv created by <code>uv</code>, and it is
incapable of figuring out what went wrong here, wasting a lot of tokens
randomly flailing around.</li></ul></content><p></p></main><footer></footer></body></html>