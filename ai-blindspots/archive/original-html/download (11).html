<!doctype html><html lang=en-us><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Use MCP Servers | AI Blindspots</title>
<meta name=title content="Use MCP Servers"><meta name=description content="Model Context Protocol servers provide a standard interface for LLMs to
interact with their environment.  Cursor Agent mode and Claude Code use agents
extensively.  For example, instead of needing a separate RAG system (e.g., as
previously provided by Cursor) to find and feed the model relevant context
files, the LLM can instead call an MCP which will let it lookup what files it
wants to look at before deciding what to do.  Similarly, a model can run tests
or build and then immediately work on fixing problems when this occurs.  It is
clear that Anthropic&rsquo;s built-in MCP servers are useful, and you should use
agent mode when you can."><meta name=keywords content><meta property="og:url" content="https://ezyang.github.io/ai-blindspots/use-mcp-servers/"><meta property="og:site_name" content="AI Blindspots"><meta property="og:title" content="Use MCP Servers"><meta property="og:description" content="Model Context Protocol servers provide a standard interface for LLMs to interact with their environment. Cursor Agent mode and Claude Code use agents extensively. For example, instead of needing a separate RAG system (e.g., as previously provided by Cursor) to find and feed the model relevant context files, the LLM can instead call an MCP which will let it lookup what files it wants to look at before deciding what to do. Similarly, a model can run tests or build and then immediately work on fixing problems when this occurs. It is clear that Anthropic’s built-in MCP servers are useful, and you should use agent mode when you can."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-03-06T11:18:04-05:00"><meta property="article:modified_time" content="2025-03-06T11:18:04-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Use MCP Servers"><meta name=twitter:description content="Model Context Protocol servers provide a standard interface for LLMs to interact with their environment. Cursor Agent mode and Claude Code use agents extensively. For example, instead of needing a separate RAG system (e.g., as previously provided by Cursor) to find and feed the model relevant context files, the LLM can instead call an MCP which will let it lookup what files it wants to look at before deciding what to do. Similarly, a model can run tests or build and then immediately work on fixing problems when this occurs. It is clear that Anthropic’s built-in MCP servers are useful, and you should use agent mode when you can."><meta itemprop=name content="Use MCP Servers"><meta itemprop=description content="Model Context Protocol servers provide a standard interface for LLMs to interact with their environment. Cursor Agent mode and Claude Code use agents extensively. For example, instead of needing a separate RAG system (e.g., as previously provided by Cursor) to find and feed the model relevant context files, the LLM can instead call an MCP which will let it lookup what files it wants to look at before deciding what to do. Similarly, a model can run tests or build and then immediately work on fixing problems when this occurs. It is clear that Anthropic’s built-in MCP servers are useful, and you should use agent mode when you can."><meta itemprop=datePublished content="2025-03-06T11:18:04-05:00"><meta itemprop=dateModified content="2025-03-06T11:18:04-05:00"><meta itemprop=wordCount content="457"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:800px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fff;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--code-background-color:#f2f2f2;--code-color:#222;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#333;--heading-color:#eee;--text-color:#ddd;--link-color:#8cc2dd;--visited-color:#8b6fcb;--code-background-color:#777;--code-color:#ddd;--blockquote-color:#ccc}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px}blockquote{border-left:1px solid #999;color:var(--code-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto!important}.highlight,.code{padding:1px 15px;background-color:var(--code-background-color);color:var(--code-color);border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style></head><body><header><a href=/ai-blindspots/ class=title><h2>AI Blindspots</h2></a><nav><a href=/ai-blindspots/>Home</a>
<a href=/ai-blindspots/blog>Blog</a></nav></header><main><h1>Use MCP Servers</h1><p><i><time datetime=2025-03-06>2025-03-06</time></i></p><content><p>Model Context Protocol servers provide a standard interface for LLMs to
interact with their environment. Cursor Agent mode and Claude Code use agents
extensively. For example, instead of needing a separate RAG system (e.g., as
previously provided by Cursor) to find and feed the model relevant context
files, the LLM can instead call an MCP which will let it lookup what files it
wants to look at before deciding what to do. Similarly, a model can run tests
or build and then immediately work on fixing problems when this occurs. It is
clear that Anthropic&rsquo;s built-in MCP servers are useful, and you should use
agent mode when you can.</p><hr><p>Epistemic status: this next section is theoretical, I have not attempted it in
practice yet.</p><p>A further question to ask is whether or not you should be writing your own MCP
servers. One of the built-in MCP servers is a shell, so in practice you can
turn on YOLO mode in Cursor and add some instructions to your Cursor rules
about what commands to run and this actually works reasonably well. But it&rsquo;s
really dangerous! Arbitrary shell commands can do anything, and there are
plenty of shell commands in your LLMs pretraining set that will trash your
environment. So you are mostly praying that your LLM doesn&rsquo;t go off the rails
some day (or you&rsquo;re a careful user and audit every command before running
them&ndash;let&rsquo;s be real, who&rsquo;s got time for that).</p><p>The alternative is to write an MCP server that exposes the commands that you
want your model to have access to (note, this is a bit different from what
most people are thinking of when they write MCPs to access various existing
platform APIs). In principle, this should make it easier to control what
tools actually end up getting called, but as of March 2025 support for this in
Cursor is poor. In particular, there is no direct way to have different MCP
servers on a per project basis, and the overall direction the ecosystem is
going with MCP servers are to provide tools that are universally applicable,
rather than the equivalent of <code>npm run</code> as an MCP server.</p><h2 id=examples>Examples</h2><ul><li>When I ask Sonnet 3.7 to typecheck a TypeScript project and fix errors, in
agent mode it will use MCP to run the command, get the output, and decide
what to do from there. There is much more convenient than having to
manually copy paste terminal output into the chat window. It&rsquo;s important to
prompt this appropriately (either in Cursor rules, or via an MCP), as the
LLM is prone to hallucinating what command you should run. For example, in
my case, by default it hallucinates <code>npm run typecheck</code>, which on this
project did not work.</li></ul></content><p></p></main><footer></footer></body></html>