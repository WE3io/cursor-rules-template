# Fundamentals

Core principles that form the foundation of effective AI assistant collaboration.

## Articles in This Category

### [Memento](memento.md)
**Memory limitations and context management**

LLMs have no persistent memory across sessions. Understanding this fundamental limitation shapes how you structure conversations and manage context.

**Key Takeaways:**
- No memory between sessions vs. full context within sessions
- Strategic session management
- Documentation for persistence
- When to restart

**Read this when:** Starting with AI assistants, confused about "memory"

---

### [Use Static Types](use-static-types.md)
**Leveraging type systems for better AI collaboration**

Type systems dramatically reduce the overhead of statically-typed languages when working with AI, enabling better refactoring and catching errors early.

**Key Takeaways:**
- Types guide LLM refactoring
- Modern LLMs handle Rust well (2026)
- Configure strict mode for gradual types
- Token cost considerations

**Read this when:** Choosing languages, planning refactoring, experiencing type errors

---

## Why These Are Fundamental

These articles cover universal principles that apply regardless of your specific use case:
- **Memory** affects every conversation
- **Types** affect code quality across all languages

Master these first, then explore domain-specific blindspots.

---

**More fundamentals coming:** Stop Digging, Requirements not Solutions, Walking Skeleton, and others will be enhanced from the original collection.

See [../../archive/original-html/](../../archive/original-html/) for the original 20 articles.
